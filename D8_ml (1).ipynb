{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bca080b6a75d3c2ab92a041690185793",
     "grade": false,
     "grade_id": "cell-8e163850806ee57f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Workbook : Machine Learning\n",
    "\n",
    "For our last section workbook (so that next week you can ask questions about and work on your final projects in section), we're going to work with a dataset all about craft beer. We'll work to predict what type of beer each is based on the characteristics of that beer.\n",
    "\n",
    "**Disclaimer**: Working with data about beer does *NOT* mean that I'm encouraging the drinking of beer by students. In fact, your professor doesn't even like beer (blech). Specifically, individuals under the age of 21 are not legally allowed to consume alcoholic beverages, but lucky for you all, that doesn't stop us from working with data on the topic!\n",
    "\n",
    "The data we'll use here come from a publicly-available [Kaggle dataset on craft beer](https://www.kaggle.com/nickhould/craft-cans)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7522e9ec3d6f8af77c7096cec0e70f0",
     "grade": false,
     "grade_id": "cell-fdf5a52cfdd2a118",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part I : Data, Wrangling, & EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3ab1afd5eecc970660ea4bbc1f1ac53",
     "grade": false,
     "grade_id": "cell-ce3ad411221e7d98",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To get started, you'll need to **import the following**:\n",
    "   * `pandas` as `pd`\n",
    "   * `numpy` as `np`\n",
    "   * from `sklearn.svm`: `SVC` \n",
    "   * from `sklearn.metrics`: `confusion_matrix`, `classification_report`, `precision_recall_fscore_support` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b815e40064b448cc28307957c386b3ce",
     "grade": false,
     "grade_id": "cell-1fa5c018cbfab919",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6245965a1e12b02e9a79a1751088bc77",
     "grade": true,
     "grade_id": "cell-d8b87114e650e607",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert pd\n",
    "assert np\n",
    "assert SVC\n",
    "assert confusion_matrix\n",
    "assert classification_report\n",
    "assert precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52ba2cc916118f90fbfd6566ff76f8f9",
     "grade": false,
     "grade_id": "cell-dcd19dacb286d745",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now that you're setup to go in Python, **read in the `'breweries.csv'` file from the `data/` directory. Assign this to the variable `breweries`**. Then, **read in the file `beers.csv` from the `data/` directory. Assign this to the variable `beers`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4152e51aad276bcf6fe7d71d298bc78d",
     "grade": false,
     "grade_id": "cell-d10db4e6f0c02976",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                       name           city state\n",
      "0           0         NorthGate Brewing     Minneapolis    MN\n",
      "1           1  Against the Grain Brewery     Louisville    KY\n",
      "2           2   Jack's Abby Craft Lagers     Framingham    MA\n",
      "3           3  Mike Hess Brewing Company      San Diego    CA\n",
      "4           4    Fort Point Beer Company  San Francisco    CA\n",
      "   Unnamed: 0    abv  ibu    id                 name  \\\n",
      "0           0  0.050  NaN  1436             Pub Beer   \n",
      "1           1  0.066  NaN  2265          Devil's Cup   \n",
      "2           2  0.071  NaN  2264  Rise of the Phoenix   \n",
      "3           3  0.090  NaN  2263             Sinister   \n",
      "4           4  0.075  NaN  2262        Sex and Candy   \n",
      "\n",
      "                            style  brewery_id  ounces  \n",
      "0             American Pale Lager         408    12.0  \n",
      "1         American Pale Ale (APA)         177    12.0  \n",
      "2                    American IPA         177    12.0  \n",
      "3  American Double / Imperial IPA         177    12.0  \n",
      "4                    American IPA         177    12.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the CSV files\n",
    "breweries = pd.read_csv(\"data/breweries.csv\")\n",
    "beers = pd.read_csv(\"data/beers.csv\")\n",
    "\n",
    "# Display the first few rows to confirm successful loading\n",
    "print(breweries.head())\n",
    "print(beers.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8603ae6e6237c1b0236d687fb8c3313",
     "grade": true,
     "grade_id": "cell-a3a4511bf1f57302",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert breweries.shape == (558, 4)\n",
    "assert beers.shape == (2410, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06be30c413f7fa03abd28a404c43b7f4",
     "grade": false,
     "grade_id": "cell-d651eaa7ddee7941",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Run the code below to take a **look at the first few rows of each dataset** to give yourself an idea of what data are inclued in each dataset. Notice if there are any common columns between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NorthGate Brewing</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Against the Grain Brewery</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>KY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jack's Abby Craft Lagers</td>\n",
       "      <td>Framingham</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mike Hess Brewing Company</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Fort Point Beer Company</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       name           city state\n",
       "0           0         NorthGate Brewing     Minneapolis    MN\n",
       "1           1  Against the Grain Brewery     Louisville    KY\n",
       "2           2   Jack's Abby Craft Lagers     Framingham    MA\n",
       "3           3  Mike Hess Brewing Company      San Diego    CA\n",
       "4           4    Fort Point Beer Company  San Francisco    CA"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breweries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>style</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>ounces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1436</td>\n",
       "      <td>Pub Beer</td>\n",
       "      <td>American Pale Lager</td>\n",
       "      <td>408</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2265</td>\n",
       "      <td>Devil's Cup</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2264</td>\n",
       "      <td>Rise of the Phoenix</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2263</td>\n",
       "      <td>Sinister</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2262</td>\n",
       "      <td>Sex and Candy</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>177</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    abv  ibu    id                 name  \\\n",
       "0           0  0.050  NaN  1436             Pub Beer   \n",
       "1           1  0.066  NaN  2265          Devil's Cup   \n",
       "2           2  0.071  NaN  2264  Rise of the Phoenix   \n",
       "3           3  0.090  NaN  2263             Sinister   \n",
       "4           4  0.075  NaN  2262        Sex and Candy   \n",
       "\n",
       "                            style  brewery_id  ounces  \n",
       "0             American Pale Lager         408    12.0  \n",
       "1         American Pale Ale (APA)         177    12.0  \n",
       "2                    American IPA         177    12.0  \n",
       "3  American Double / Imperial IPA         177    12.0  \n",
       "4                    American IPA         177    12.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8324e86eec63855c04aa0491be6d8800",
     "grade": false,
     "grade_id": "cell-22e091210d7e94cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To get a quick handle on what's going on these data, **save the number of missing values in each variable of the variables in the `beers` dataset to `null_beers`.** Hint: use `.isnull()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "774d4e02f58fc38b07de945f4042061f",
     "grade": false,
     "grade_id": "cell-d97505cb97ec42e8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0       0\n",
      "abv             62\n",
      "ibu           1005\n",
      "id               0\n",
      "name             0\n",
      "style            5\n",
      "brewery_id       0\n",
      "ounces           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_beers = None\n",
    "#Count the number of missing values in each variable of the beers dataset and save it to null_beers.\n",
    "null_beers = beers.isnull().sum()\n",
    "print(null_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91fc9a97a3312f625c6b3707a50ab4c8",
     "grade": true,
     "grade_id": "cell-3cd490ad836a8c93",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert null_beers.sum() == 1072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c6c787887b7798bd8eb0e6955d1de2d",
     "grade": false,
     "grade_id": "cell-426ea7870467bb28",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We're going to try to predict the `style` of beer from its alcohol by volume (`abv`) and its international bitterness unites (`ibu`). To do this, **remove any beers from our `beers` dataset where data are missing for any of these three values. Store this back into hte `beers` dataset.** \n",
    "\n",
    "Note that you may not always want to take this approach and removing samples from your dataset will not always be appropriate, but for this example, it's a reasonable approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77a8dc0e06680bf004ab0e905f6c51fb",
     "grade": false,
     "grade_id": "cell-388ac707168e1d78",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0    abv   ibu    id                                  name  \\\n",
      "14          14  0.061  60.0  1979                          Bitter Bitch   \n",
      "21          21  0.099  92.0  1036                         Lower De Boom   \n",
      "22          22  0.079  45.0  1024                         Fireside Chat   \n",
      "24          24  0.044  42.0   876                       Bitter American   \n",
      "25          25  0.049  17.0   802  Hell or High Watermelon Wheat (2009)   \n",
      "\n",
      "                      style  brewery_id  ounces  \n",
      "14  American Pale Ale (APA)         177    12.0  \n",
      "21      American Barleywine         368     8.4  \n",
      "22            Winter Warmer         368    12.0  \n",
      "24  American Pale Ale (APA)         368    12.0  \n",
      "25   Fruit / Vegetable Beer         368    12.0  \n",
      "Beers DataFrame shape: (1403, 8)\n"
     ]
    }
   ],
   "source": [
    "#Remove Rows with Missing Values\n",
    "beers = beers.dropna(subset=['style', 'abv', 'ibu'])\n",
    "print(beers.head())  # Display the first few rows to confirm successful removal\n",
    "print(\"Beers DataFrame shape:\", beers.shape)\n",
    "assert beers.shape == (1403, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9ad4f529a02e1674c1846ec5c553467",
     "grade": true,
     "grade_id": "cell-a4e2eedae6534f9d",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert beers.shape == (1403, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07f352c73d0a0080d77898d5817231e8",
     "grade": false,
     "grade_id": "cell-fa4c8beae4ab7988",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Using the `beers` dataset you've not got, **merge `beers` and `breweries` together using a left join. Assign this to the variable `beer_df`. Be sure to look at the first few rows of `beer_df`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afb0dc1a3768ea953f0cd4f17985f9a4",
     "grade": false,
     "grade_id": "cell-3f94ee193183fa7d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breweries DataFrame shape: (558, 4)\n",
      "      abv   ibu    id                                name_x  \\\n",
      "14  0.061  60.0  1979                          Bitter Bitch   \n",
      "21  0.099  92.0  1036                         Lower De Boom   \n",
      "22  0.079  45.0  1024                         Fireside Chat   \n",
      "24  0.044  42.0   876                       Bitter American   \n",
      "25  0.049  17.0   802  Hell or High Watermelon Wheat (2009)   \n",
      "\n",
      "                      style  brewery_id  ounces                  name_y  \\\n",
      "14  American Pale Ale (APA)         177    12.0     18th Street Brewery   \n",
      "21      American Barleywine         368     8.4  21st Amendment Brewery   \n",
      "22            Winter Warmer         368    12.0  21st Amendment Brewery   \n",
      "24  American Pale Ale (APA)         368    12.0  21st Amendment Brewery   \n",
      "25   Fruit / Vegetable Beer         368    12.0  21st Amendment Brewery   \n",
      "\n",
      "             city state  \n",
      "14           Gary    IN  \n",
      "21  San Francisco    CA  \n",
      "22  San Francisco    CA  \n",
      "24  San Francisco    CA  \n",
      "25  San Francisco    CA  \n",
      "Merged DataFrame shape: (1403, 10)\n",
      "Merged DataFrame columns: Index(['abv', 'ibu', 'id', 'name_x', 'style', 'brewery_id', 'ounces', 'name_y',\n",
      "       'city', 'state'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge Datasets\n",
    "print(\"Breweries DataFrame shape:\", breweries.shape)\n",
    "beer_df = pd.merge(beers, breweries, left_on='brewery_id', right_index=True, how='left')\n",
    "\n",
    "# Drop the unwanted columns\n",
    "beer_df = beer_df.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'])\n",
    "\n",
    "print(beer_df.head())  # Display the first few rows to confirm successful merge\n",
    "print(\"Merged DataFrame shape:\", beer_df.shape)\n",
    "print(\"Merged DataFrame columns:\", beer_df.columns)\n",
    "assert beer_df.shape == (1403, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d776c81defd42305062f804f182a8e77",
     "grade": true,
     "grade_id": "cell-41b5dd9436fa816f",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert beer_df.shape == (1403, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cc477c9f87650f6721db82a99e61016",
     "grade": false,
     "grade_id": "cell-b52a63d3b3ec5f7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Use and take a look at the output of the `describe()` method to describe the quantitative variables in your `beer_df` dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be sure to look at the output you just generated. What do you learn? Do any values surprise you? Are there any with really big standard deviations? Does this make sense?** (Feel free to edit this cell with any observations/notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "510aea1ce29b4ab6f5f0415558cfc9c6",
     "grade": false,
     "grade_id": "cell-34e34f4882c37e4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now, let's take a look and **see how many different styles of beer we have in our datset.** The `value_counts` method may help you accomplish this. Assign it to `beer_counts` and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad558068126dfeb5ffd0045e9e2f34a2",
     "grade": false,
     "grade_id": "cell-f6596e92382da73f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "beer_counts = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(beer_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1987758b93e2cf9364d9b0f87db8e96",
     "grade": true,
     "grade_id": "cell-7088071ffa9cd420",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert beer_counts[0] == 301\n",
    "assert len(beer_counts) == 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b6d050bd28ef500b84afef9fb138ade",
     "grade": false,
     "grade_id": "cell-7d90c30fa7af6516",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Due to limitations in time here in section, let's just try to predict the four most common `style`s of beer. **Filter your `beer_df` dataset to only include entries from the four most common `style`s of beer.** Store this filtered dataset into `beer_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb8b649dd11f4c45717162b787d30ae6",
     "grade": false,
     "grade_id": "cell-48c99ba398ca62d3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "style\n",
      "American IPA                          301\n",
      "American Pale Ale (APA)               153\n",
      "American Amber / Red Ale               77\n",
      "American Double / Imperial IPA         75\n",
      "American Blonde Ale                    61\n",
      "                                     ... \n",
      "Roggenbier                              1\n",
      "Smoked Beer                             1\n",
      "Euro Pale Lager                         1\n",
      "Other                                   1\n",
      "American Double / Imperial Pilsner      1\n",
      "Name: count, Length: 90, dtype: int64\n",
      "Filtered DataFrame shape: (606, 10)\n",
      "Unique styles in filtered DataFrame: ['American Pale Ale (APA)' 'American IPA' 'American Double / Imperial IPA'\n",
      " 'American Amber / Red Ale']\n"
     ]
    }
   ],
   "source": [
    "# Count the number of different styles of beer\n",
    "beer_counts = beer_df['style'].value_counts()\n",
    "print(beer_counts)\n",
    "\n",
    "# Filter the beer_df dataset to only include entries from the four most common styles\n",
    "most_common_styles = beer_counts.index[:4]\n",
    "beer_df = beer_df[beer_df['style'].isin(most_common_styles)]\n",
    "\n",
    "# Print the shape of the DataFrame and the unique styles to check the filtering\n",
    "print(\"Filtered DataFrame shape:\", beer_df.shape)\n",
    "print(\"Unique styles in filtered DataFrame:\", beer_df['style'].unique())\n",
    "\n",
    "# Check the assertion\n",
    "assert beer_df.shape == (606, 10)\n",
    "styles = beer_df['style'].value_counts().index.tolist()\n",
    "assert len(styles) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d42c985c1084ba2fc6950f1e83f04c0f",
     "grade": true,
     "grade_id": "cell-0e32bba1df972c3f",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert beer_df.shape == (606, 10)\n",
    "styles = beer_df['style' ].value_counts().index.tolist()\n",
    "assert len(styles) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "032f48760f03c1b8a94614909b4bb7b5",
     "grade": false,
     "grade_id": "cell-3ab868e2e0d255fe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part II : Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b028fcbcb89297879b7982ab339b2edb",
     "grade": false,
     "grade_id": "cell-b12ae6d6f7db673a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's start to build our model! To do so, **create a variable `num_training` that includes the number of samples that corresponds to 80% of our total samples in our `beer_df` dataset. Be sure that this is an integer. Also, create a variable `num_testing` including the number corresponding to 20% of our total samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b8acbbc26c81a0128b70291421e481c",
     "grade": false,
     "grade_id": "cell-f165209e70ea6449",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 484\n",
      "Number of testing samples: 122\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of training and testing samples\n",
    "num_samples = beer_df.shape[0]\n",
    "num_training = int(num_samples * 0.8)  # 80% of the total samples\n",
    "num_testing = num_samples - num_training  # Remaining 20% of the total samples\n",
    "\n",
    "print(\"Number of training samples:\", num_training)\n",
    "print(\"Number of testing samples:\", num_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12bf0785e60e648bf4428f2450b029eb",
     "grade": true,
     "grade_id": "cell-e1d7bf7037d83e71",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert num_training == 484\n",
    "assert num_testing == 122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67c7d0b9167ad61b820326b749401dbf",
     "grade": false,
     "grade_id": "cell-e79d09b67d706714",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To model these data, **split your data into `beer_X`, which includes the `abv` and `ibu` columns from `beer_df` (predictors). This should be a `pandas` DataFrame. The outcome variable will be `style`. Assign the outcome variable to the variable `beer_Y`. This should be a `numpy` array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11f64e8b1c309cdbe295d833527a713c",
     "grade": false,
     "grade_id": "cell-09abd08ce060707e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      abv   ibu\n",
      "14  0.061  60.0\n",
      "24  0.044  42.0\n",
      "28  0.070  70.0\n",
      "29  0.070  70.0\n",
      "30  0.070  70.0\n",
      "['American Pale Ale (APA)' 'American Pale Ale (APA)' 'American IPA'\n",
      " 'American IPA' 'American IPA']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Split the data into predictors (beer_X) and the outcome variable (beer_Y)\n",
    "beer_X = beer_df[['abv', 'ibu']]  # Select the abv and ibu columns as predictors\n",
    "beer_Y = beer_df['style'].values  # Select the style column as the outcome variable and convert to a numpy array\n",
    "\n",
    "print(beer_X.head())  # Display the first few rows of beer_X\n",
    "print(beer_Y[:5])     # Display the first few elements of beer_Y to confirm the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5806ad12c4af30483e48be3f10356ff",
     "grade": true,
     "grade_id": "cell-1e3c377f346c42a5",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(beer_Y) == np.ndarray\n",
    "assert beer_Y.shape == (606,)\n",
    "assert beer_X.shape == (606, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf3f431df5efd0af0add1d4b6d2c00f7",
     "grade": false,
     "grade_id": "cell-3b4ef319727cbb8b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Before running our model, we'll need to **split our data into a training and test set. Use `num_training` (created above) to extract the following variables**: \n",
    "* from `beer_X`, generate : `beer_train_X`, `beer_test_X`\n",
    "* from `beer_Y`, generate: `beer_train_Y`, `beer_test_Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13799013bce30e14fb69ca3097b1edda",
     "grade": false,
     "grade_id": "cell-fd8962674731f8e3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dba88a86ce20807f334f4938e90ef93b",
     "grade": true,
     "grade_id": "cell-2eec1a76d54f17cd",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(beer_train_X) == 484\n",
    "assert len(beer_test_X) == 122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8ccda306461e953e03f2ff33e68bf7e",
     "grade": false,
     "grade_id": "cell-e6539ca3c26cf51d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To train our model, we'll use a linear SVM classifier. Here a function has been defined for you. **Run the following cell, but be sure you understand what the function is doing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM(X, y, kernel='linear'):\n",
    "    clf = SVC(kernel=kernel)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c60ca345507c724c8e0f6d253ab2cf3d",
     "grade": false,
     "grade_id": "cell-3be55a85ea1c8548",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Using the `train_SVM` function defined above, **train your model. Assign this output to `beer_clf`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29d83d670688d72f56ac16e9fbaf2f21",
     "grade": false,
     "grade_id": "cell-c206bff1f25a305d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2ea19015c1cd02a3bde33d7a13ac56f",
     "grade": true,
     "grade_id": "cell-dabc42c110c1d9d3",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(beer_clf, SVC)\n",
    "assert hasattr(beer_clf, \"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1faa40189cfc8d5e6e0010fa72d35263",
     "grade": false,
     "grade_id": "cell-beecc192f751ea14",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now, **generate predictions from your training and test sets of predictors using the `predict` method. Assign your predictions from the training data to `beer_predicted_train_Y`. Assign your predictison from the test data to `beer_predicted_test_Y`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66111a02bdebc153ab5612c08f12393e",
     "grade": false,
     "grade_id": "cell-2a2fef981469581b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93ac6e84bc220c20e544aa846b03f31c",
     "grade": true,
     "grade_id": "cell-64a1bcc16fea4e57",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert beer_predicted_train_Y.shape == (484,)\n",
    "assert beer_predicted_test_Y.shape == (122,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3fe08ec00069f19077259c125222d2a",
     "grade": false,
     "grade_id": "cell-597175267bdb0dd1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part III : Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce467c5501d5c83260bfbd7ab615350f",
     "grade": false,
     "grade_id": "cell-067170c37cfeea01",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "At this point, you should have built your model and generated predictions using that model for both your training and test datasets. \n",
    "\n",
    "Let's determine how our predictor did. **Generate a `classification_report` from sklearn for the predictions generated for your training data relative to the truth (from the original beers dataset). Save the output to `class_report_train` and print it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52cca7e45abd6f1135c3ebcccbd2f065",
     "grade": false,
     "grade_id": "cell-5cc9c9d3cca4e6ce",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictors shape: (484, 2)\n",
      "Test predictors shape: (122, 2)\n",
      "Training outcome shape: (484,)\n",
      "Test outcome shape: (122,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class_report_train = None\n",
    "# Split the predictors (beer_X) and outcome variable (beer_Y) into training and test sets\n",
    "beer_train_X = beer_X[:num_training]\n",
    "beer_test_X = beer_X[num_training:]\n",
    "beer_train_Y = beer_Y[:num_training]\n",
    "beer_test_Y = beer_Y[num_training:]\n",
    "\n",
    "print(\"Training predictors shape:\", beer_train_X.shape)\n",
    "print(\"Test predictors shape:\", beer_test_X.shape)\n",
    "print(\"Training outcome shape:\", beer_train_Y.shape)\n",
    "print(\"Test outcome shape:\", beer_test_Y.shape)\n",
    "print(class_report_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08728079d0b38e1087151092914ab602",
     "grade": true,
     "grade_id": "cell-286c81688153a523",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclass_report_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m578\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "assert len(class_report_train) == 578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89e9425f3cbfd78cd20733d62106049b",
     "grade": false,
     "grade_id": "cell-6681443e553ac9ac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What are precision and recall? What do these numbers represent? How accurate are our predictions?\n",
    "\n",
    "**Generate a `classification_report_test` for the predictions generated for your *test* data relative to the truth (from the original beers dataset). Save the output to `class_report_test` and print it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "101207e1e778daeab598400e902ec9d1",
     "grade": false,
     "grade_id": "cell-82e29dc9780e9d89",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class_report_test = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(class_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9e1a537bd9d62512ca50d8238fef212",
     "grade": true,
     "grade_id": "cell-90c55c6bf37fdf0e",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(class_report_test) == 578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7a8eaea544dfe66a0233cd45cf4d35f",
     "grade": false,
     "grade_id": "cell-f095533f7c6debfa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "How is our model performing? Does this dffer between training and test data? Where does it have trouble? Where does it perform well? Do we have thoughts as to why? One way to determine where a model is going wrong is to look at a confusion matrix. **Generate a confusion matrix for the training data predictions as well as the ground truth from the `beer_df` dataset. Save this to `conf_mat_train`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c3f25413dbeba82cfd6c032cd6a8507",
     "grade": false,
     "grade_id": "cell-f0a1f8d304bd71ae",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Training):\n",
      "[[ 63   1   1   5]\n",
      " [  0  57   0   0]\n",
      " [  0   0 221  15]\n",
      " [  3   0   4 114]]\n",
      "[[ 63   1   1   5]\n",
      " [  0  57   0   0]\n",
      " [  0   0 221  15]\n",
      " [  3   0   4 114]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_train = None\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming beer_X and beer_Y are already loaded as DataFrame or arrays\n",
    "# Split the data into training and test sets\n",
    "beer_train_X, beer_test_X, beer_train_Y, beer_test_Y = train_test_split(beer_X, beer_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(beer_train_X, beer_train_Y)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions = clf.predict(beer_train_X)\n",
    "\n",
    "# Generate the confusion matrix for the training set\n",
    "conf_mat_train = confusion_matrix(beer_train_Y, train_predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix (Training):\")\n",
    "print(conf_mat_train)\n",
    "print(conf_mat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae80b4dabd73ca28bf6209e699b7c7fa",
     "grade": true,
     "grade_id": "cell-c91192ed7ddfc166",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m conf_mat_train[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m31\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m conf_mat_train[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m81\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m conf_mat_train\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert conf_mat_train[0,0] == 31\n",
    "assert conf_mat_train[-1,-1] == 81\n",
    "assert conf_mat_train.shape == (4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71d90ec181db6a4b60ec9afbcd9581b3",
     "grade": false,
     "grade_id": "cell-62b89740a5653fda",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Generate a confusion matrix for the testing data. Save this to `conf_mat_test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0988a9ee91c1a83657f9cd609eca16c1",
     "grade": false,
     "grade_id": "cell-dcfae2fde6f81ba9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "conf_mat_test = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(conf_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbba90836d2268178d76951b6d123b81",
     "grade": true,
     "grade_id": "cell-e422ac70e62a9759",
     "locked": true,
     "points": 0.125,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert conf_mat_test[-1,-1] == 21\n",
    "assert conf_mat_test.shape == (4,4)\n",
    "assert conf_mat_test[0,0] == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "749df6ba0235aa851725e71c3ea39717",
     "grade": false,
     "grade_id": "cell-5a8ce05a47852654",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "While this is a somewhat small example using a limited dataset for prediction, we hope you have a better understanding of how to approach a machine learning question, knowing specifically what training and test datasets are used for, how to build a model, and how to assess model/prediction performance. **Feel free to try different models, include more beer types in your analysis or ask a completely different prediction question!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
