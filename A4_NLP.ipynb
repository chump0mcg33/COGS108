{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50a7eb8ed9946619ef9fd3cd4894a0e5",
     "grade": false,
     "grade_id": "cell-70c15471327b6620",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# COGS 108 - Assignment 4: Natural Language Processing\n",
    "\n",
    "This assignment covers working with text data and NLP.\n",
    "\n",
    "This assignment is out of 8 points, worth 8% of your grade.\n",
    "\n",
    "**PLEASE DO NOT CHANGE THE NAME OF THIS FILE.**\n",
    "\n",
    "**PLEASE DO NOT COPY & PASTE OR DELETE CELLS INLCUDED IN THE ASSIGNMENT.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f531ea4a365ceb09d85090e09f7336fb",
     "grade": false,
     "grade_id": "cell-8499cb794c95ec9d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Important\n",
    "\n",
    "- This assignment has hidden tests: tests that are not visible here, but that will be run on your submitted assignment for grading.\n",
    "    - This means passing all the tests you can see in the notebook here does not guarantee you have the right answer!\n",
    "    - In particular many of the tests you can see simply check that the right variable names exist. Hidden tests check the actual values. \n",
    "        - It is up to you to check the values, and make sure they seem reasonable.\n",
    "- A reminder to restart the kernel and re-run the code as a first line check if things seem to go weird.\n",
    "    - For example, note that some cells can only be run once, because they re-write a variable (for example, your dataframe), and change it in a way that means a second execution will fail. \n",
    "    - Also, running some cells out of order might change the dataframe in ways that may cause an error, which can be fixed by re-running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df129e864f32eb073a5721b3e75fbc7b",
     "grade": false,
     "grade_id": "cell-6b464efd2fb5aabd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Background & Work Flow\n",
    "\n",
    "- In this homework assignment, we will be analyzing text data. A common approach to analyzing text data is to use methods that allow us to convert text data into some kind of numerical representation - since we can then use all of our mathematical tools on such data. In this assignment, we will explore 2 feature engineering methods that convert raw text data into numerical vectors:\n",
    "    - **Bag of Words (BoW)**\n",
    "        - BoW encodes an input sentence as the frequency of each word in the sentence. \n",
    "        - In this approach, all words contribute equally to the feature vectors.\n",
    "    - **Term Frequency - Inverse Document Frequency (TF-IDF)**\n",
    "        - TF-IDF is a measure of how important each term is to a specific document, as compared to an overall corpus. \n",
    "        - TF-IDF encodes each word as its frequency in the document of interest, divided by a measure of how common the word is across all documents (the corpus).\n",
    "        - Using this approach, each word contributes differently to the feature vectors.\n",
    "        - The assumption behind using TF-IDF is that words that appear commonly everywhere are not that informative about what is specifically interesting about a document of interest, so it is tuned to representing a document in terms of the words it uses that are different from other documents. \n",
    "\n",
    "- To compare those 2 methods, we will first apply them on the same Movie Review dataset to analyze sentiment (how positive or negative a text is). In order to make the comparison fair, an **SVM (support vector machine)** classifier will be used to classify positive reviews and negative reviews.\n",
    "\n",
    "- SVM is a simple yet powerful and interpretable linear model. To use it as a classifier, we need to have at least 2 splits of the data: training data and test data. The training data is used to tune the weight parameters in the SVM to learn an optimal way to classify the training data. We can then test this trained SVM classifier on the test data, to see how well it works on data that the classifier has not seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f63e1844f8a30eea74bd83c5f95d294",
     "grade": false,
     "grade_id": "Imports",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports - these are all the imports needed for the assignment\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import nltk package \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5632b559471c292d87ec10648f5ba360",
     "grade": false,
     "grade_id": "cell-d96a6fcbdcbed177",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "For this assignment we will be using `nltk`: the Natural Language Toolkit.\n",
    "\n",
    "To do so, we will need to download some text data.\n",
    "\n",
    "Natural language processing (NLP) often requires corpus data (lists of words, and/or example text data) which is what we will download here now, if you don't already have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "490a4616aa7faae36ae7a667175c11f7",
     "grade": false,
     "grade_id": "cell-04e576aebbcdfe34",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Download the NLTK English tokenizer and the stopwords of all languages\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24a0b3abfec4714eceedc8a9d86532ad",
     "grade": false,
     "grade_id": "cell-c728326960d37d88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part 1: Sentiment Analysis on Movie Review Data (4.75 points)\n",
    "\n",
    "In part 1 we will apply sentiment analysis to Movie Review (MR) data.\n",
    "\n",
    "- The MR data contains more than 10,000 reviews collected from the IMDB website, and each of the reviews is annotated as either positive or negative. The number of positive and negative reviews are roughly the same. For more information about the dataset, you can visit http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "- For this homework assignment, we've already shuffled the data, and truncated the data to contain only 5000 reviews.\n",
    "\n",
    "In this part of the assignment we will:\n",
    "- Transform the raw text data into vectors with the BoW encoding method\n",
    "- Split the data into training and test sets\n",
    "- Write a function to train an SVM classifier on the training set\n",
    "- Test this classifier on the test set and report the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31731cce0f556f228ee1111fbef0c901",
     "grade": false,
     "grade_id": "cell-7ae64525daa7892e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1a) Import data\n",
    "\n",
    "Import the file with the url `https://raw.githubusercontent.com/COGS108/A4_Data/refs/heads/main/data/rt-polarity.tsv` into a DataFrame called `movie_df`. This file is large and may take some time to import.\n",
    "\n",
    "Note that this file is a tab separated raw text file, in which data is separated by tabs. You can load this file with `pd.read_csv`, but we have to tell function to use tabs instead of commas as the column separator.  Look at the docs for `pd.read_csv` to figure out how to use tab as the column separator. \n",
    "\n",
    "The file doesn't have a set of column names in the first row, it just starts with data.  Therefore you will have to set the argument `header` as `None` to prevent pandas from thinking data is column names. After loading the data you will have to set the column names properly.  Call them 'index', 'label', and 'review' in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88eedab80a7514a2ff88657341259940",
     "grade": false,
     "grade_id": "Q-1a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa1a5a308a8bf664bdcec9745ea8eb94",
     "grade": true,
     "grade_id": "A-1a",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(movie_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fe73ee67fd46c114ab5de6b49100cdf",
     "grade": false,
     "grade_id": "cell-40dae07b7eed27b1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check the data\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d037f6ada62e50c5a9c9ece2d4d08f3b",
     "grade": false,
     "grade_id": "cell-e58856b30bc3af1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1b) Create a function that converts string labels to numerical labels\n",
    "\n",
    "Function name: `label_converter`\n",
    "\n",
    "The function should do the following:\n",
    "- take two parameters `label` and `direction`\n",
    "- if `direction` is 'tonumber', \n",
    "    - and if the input `label` is \"pos\" return `1.0`\n",
    "    - and if the input `label` is \"neg\" return `0.0`\n",
    "    - otherwise, return the input `label` as is\n",
    "- if `direction` is 'tolabel'\n",
    "    - and if the input `label` is `1.0` return \"pos\"\n",
    "    - and if the input `label` is `0.0` return \"neg\"\n",
    "    - otherwise, return the `label` as is\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34df8e81740694660169c28ddbdc04ad",
     "grade": false,
     "grade_id": "Q-1b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a576ecf1fd0f88035cb92fd7e5c78f2",
     "grade": true,
     "grade_id": "A-1b",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert label_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fcc88c834f726874f90396dccda3ef9",
     "grade": true,
     "grade_id": "cell-55d9711476789ee6",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(label_converter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f410625eb171c9c26f63ba944c72e6c",
     "grade": false,
     "grade_id": "cell-55cca598b0986137",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1c) Numerical Labels\n",
    "\n",
    "Convert all labels in `movie_df[\"label\"]` to **numerical labels**, using the `label_converter` function. Be sure to specify the appropriate argument to the `direction` parameter.\n",
    "\n",
    "Save them as a new column named \"Y\" in `movie_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4daa25502cde5195c545154ed2009e33",
     "grade": false,
     "grade_id": "Q-1c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ef23e195cd117fcff720119ba65f52f",
     "grade": true,
     "grade_id": "A-1c",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert sorted(set(movie_df['Y'])) == [0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66dcf9e8e06a0d44458c9f8500b72c21",
     "grade": false,
     "grade_id": "cell-cd37ee3f688aaaec",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check the movie_df data\n",
    "movie_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94d9229079d858ca5a024a48b14aaefb",
     "grade": false,
     "grade_id": "cell-3b9ae1c6a8d22bfa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1d) Defining the train & test sets\n",
    "\n",
    "Now, we'll instead use `sklearn`'s `train_test_split()` function here to define our train and test set. Store input data (predictors) into training data `movie_train_X` and testing data `movie_test_X`. Simlarly, store labels (outcomes) into training data `movie_train_Y`and testing data `movie_test_Y`.\n",
    "\n",
    "In addition to providing the predictors (`movie_df['review']`) and outcomes (`movie_df['Y']`) to the function, we will use the following arguments for this task:\n",
    "- `test_size`: 0.2\n",
    "- `random_state`: 108\n",
    "\n",
    "\n",
    "To prepare the input data for later vectorization, convert `movie_train_X` and `movie_test_X` into lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e298ab23819a9a4594044f2a0093de8d",
     "grade": false,
     "grade_id": "Q-1g",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd4d1d657cc026c3a80fedf01af39caa",
     "grade": true,
     "grade_id": "A-1h",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(movie_train_X) == movie_train_Y.shape[0]\n",
    "assert len(movie_test_X) == movie_test_Y.shape[0]\n",
    "\n",
    "assert type(movie_train_X) == list\n",
    "assert type(movie_test_X) == list\n",
    "\n",
    "assert len(movie_train_X) == 4000\n",
    "assert len(movie_test_Y) == 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d623967017843e4dff7ccd790ae78ec",
     "grade": false,
     "grade_id": "cell-ec55be6eb56c03a9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1e) Convert text data into vector \n",
    "\n",
    "We will now create a `CountVectorizer` object to transform the text data into vectors with numerical values. \n",
    "A `CountVectorizer` converts text into numbers by:\n",
    "\n",
    "1. Reading Text: It takes sentences or a bunch of words as input.\n",
    "2. Finding Unique Words: It looks at all the words and makes a list of unique words.\n",
    "3. Counting Words: For each sentence, it counts how many times each unique word appears.\n",
    "\n",
    "The output of a `CountVectorizer` is a matrix with each row representing a sentence and each column representing a unique word. The value represents how many times each unique word appears in each sentence.\n",
    "\n",
    "We will initialize a `CountVectorizer` object, and name it as `vectorizer`.\n",
    "\n",
    "We need to pass 4 arguments to initialize a CountVectorizer:\n",
    "  1. `analyzer`: `'word'` \n",
    "          Specify to analyze data from word-level.\n",
    "  2. `max_features`: `2100`\n",
    "          Set a max number of unique words.\n",
    "  3. `tokenizer`: `word_tokenize`\n",
    "          Set to tokenize the text data by using the word_tokenizer from NLTK .\n",
    "  4. `stop_words`: `stopwords.words('english')`\n",
    "          Set to remove all stopwords in English. We do this since they generally don't provide useful discriminative information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9a46f710926e62bd3c0bce5c787892c",
     "grade": false,
     "grade_id": "Q-1d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0866e2c86beb29887dff4db5ca3ca172",
     "grade": true,
     "grade_id": "A-1d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert vectorizer.analyzer == 'word'\n",
    "assert vectorizer.max_features == 2100\n",
    "assert vectorizer.tokenizer == word_tokenize\n",
    "assert vectorizer.stop_words == stopwords.words('english')\n",
    "assert hasattr(vectorizer, \"fit_transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22b02c88d6c1d0d029ce676354fed812",
     "grade": false,
     "grade_id": "cell-a60876e4262f29a7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1f) Vectorize training reviews\n",
    "\n",
    "After we create a `CountVectorizer` object, we need to fit the `CountVectorizer` to build a consistent vocabulary by:\n",
    "1. Looking at all the text you provide and identifying every unique word. This vocabulary is a list of all the unique words that the CountVectorizer will use as features.\n",
    "2. Assigning each unique word an index (position) in the vocabulary, which will later be used to construct the word count matrix.\n",
    "\n",
    "Fit the `vectorizer` we created above using `movie_train_X` and transform the training data inputs `movie_train_X` into vectors. Save the transformed training input as `movie_train_counts` and make sure to convert the result into a numpy array.\n",
    "\n",
    "HINT: use the sklearn docs to see how to fit / transform a `CountVectorizer` object.  And you should definitely understand the difference between fit and transform.  And docs might also help you in converting the result to numpy array.\n",
    "\n",
    "NOTE: this operation may throw a warning about stopwords. This is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71df5e1cf7bf8e3995eebd5197354390",
     "grade": false,
     "grade_id": "Q-1e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "vocabulary_train = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0175049597ef5e944d040953c2c2afe",
     "grade": true,
     "grade_id": "A-1e",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(movie_train_counts) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66ef9c6d46905703294e7bc52eb53a65",
     "grade": false,
     "grade_id": "cell-6a10df0525cf971c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1g) Vectorize testing reviews\n",
    "\n",
    "Now let's turn the testing data inputs `movie_test_X` into vectors using the `vectorizer` we created above. \n",
    "\n",
    "Think about the machine learning examples we've covered in class. \n",
    "\n",
    "Ask yourself:\n",
    "- what dataset should the transformer be fit on, training or test?\n",
    "- after fitting the transformer, how can you transform a different dataset without refitting it?  \n",
    "\n",
    "Store the transformed testing data inputs as `movie_test_counts` and convert it into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2087a2186327f86f069b947b09cb4814",
     "grade": false,
     "grade_id": "Q-1f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "vocabulary_test = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cc8a90756170f27caa68463dd828e4b",
     "grade": true,
     "grade_id": "A-1f",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(movie_test_counts) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fbfdd5a9069ab146b47c82776b71e71",
     "grade": false,
     "grade_id": "Q-1i",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_SVM(X, y, kernel='linear'):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "601a78103d13843877a5e66da82a1e9e",
     "grade": true,
     "grade_id": "A-1i",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(train_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0181d55a0cbad5a6811df404fed997d5",
     "grade": false,
     "grade_id": "cell-f6a7b7746e81a1e8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1j) Train SVM\n",
    "\n",
    "Train an SVM classifier with the default linear kernel on the samples `movie_train_counts` and the labels `movie_train_Y`\n",
    "\n",
    "You need to call the function `train_SVM` you just created. Name the returned object as `movie_classifier`.\n",
    "\n",
    "Note: training your model may take many seconds / up to a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "045b0b73c674e9ea174a52a6159cd14d",
     "grade": false,
     "grade_id": "Q-ij",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5be6bef545a0198e22a0f3ba8cca464",
     "grade": true,
     "grade_id": "A-ij",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(movie_classifier, SVC)\n",
    "assert hasattr(movie_classifier, \"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83a0e59868b66e965798d77e51e710ff",
     "grade": false,
     "grade_id": "cell-d3f56db518a7fe0b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1k) Predict outcome\n",
    "\n",
    "Predict labels for both training samples and test samples. You will need to use `movie_classifier.predict(...)`\n",
    "\n",
    "Name the predicted labels for the **training samples** as `movie_predicted_train_Y`.\n",
    "Name the predicted labels for the **testing samples** as `movie_predicted_test_Y`.\n",
    "\n",
    "Note: Your code here will also take a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92659f65db8bb439049106ef91a1de1b",
     "grade": false,
     "grade_id": "Q-k",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "803b99a1647d3f2fcc48e6dddecb55e2",
     "grade": false,
     "grade_id": "cell-020455c9d9568651",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we will use the function `classification_report` to print out the performance of the classifier on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04a9f3b1f88c793bc99acab3476f67c1",
     "grade": false,
     "grade_id": "cell-fc5799e344e24b69",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Your classifier should be able to reach above 90% accuracy \n",
    "# on the training set\n",
    "print(classification_report(movie_train_Y,movie_predicted_train_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cc7d4b45837fca1e3e0ec54d539d6cf",
     "grade": false,
     "grade_id": "cell-2671503286c309f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "And finally, we check the performance of the trained classifier on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7ce5c680712c441abbb2c889bed8e1f",
     "grade": false,
     "grade_id": "cell-9fc925527bb32076",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Your classifier should be able to reach around 69% accuracy on the test set.\n",
    "print(classification_report(movie_test_Y, movie_predicted_test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b93036669c316561d87ee8be55f99b3c",
     "grade": true,
     "grade_id": "A-1k",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert movie_predicted_train_Y.shape == (4000,)\n",
    "assert movie_predicted_test_Y.shape == (1000,)\n",
    "\n",
    "precision, recall, _, _ = precision_recall_fscore_support(movie_train_Y,movie_predicted_train_Y)\n",
    "assert np.isclose(precision[0], 0.91, 0.02)\n",
    "assert np.isclose(precision[1], 0.92, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c452e81ec2813cfd0908af204d84cd3",
     "grade": false,
     "grade_id": "cell-1f649bb709859c3e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part 2: TF-IDF (1.5 points)\n",
    "\n",
    "In this part, we will explore TF-IDF on sentiment analysis.\n",
    "\n",
    "TF-IDF is used as an alternate way to encode text data, as compared to the Counts BoW approach used in Part 1. \n",
    "\n",
    "At this point you should probably ask yourself if you understand the difference between Counts and TF-IDF.  If you aren't clear this is a good time to talk to whoever is leading your dicsussion section :)\n",
    "\n",
    "To get this done we will:\n",
    "- Transform the raw text data into vectors using TF-IDF\n",
    "- Train an SVM classifier on the training set and report the performance this classifer on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73e44df839ac25a290880625a36e6c31",
     "grade": false,
     "grade_id": "cell-247ceced075ac236",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2a) Text Data to Vectors\n",
    "\n",
    "We will create a `TfidfVectorizer` object to transform the text data into vectors with TF-IDF\n",
    "\n",
    "To do so, we will initialize a `TfidfVectorizer` object, and name it as `tf_idf`.\n",
    "\n",
    "We need to pass 4 arguments into the \"TfidfVectorizer\" to initialize a \"tf_idf\":\n",
    "  1. `sublinear_tf`: `True`\n",
    "           Set to apply TF scaling.\n",
    "  2. `analyzer`: `'word'`\n",
    "           Set to analyze the data at the word-level\n",
    "  3. `max_features`: `2100`\n",
    "           Set the max number of unique words\n",
    "  4. `tokenizer`: `word_tokenize`\n",
    "           Set to tokenize the text data by using the word_tokenizer from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce1bcc99352ae5525881d3bbf044ec70",
     "grade": false,
     "grade_id": "Q-2a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca79c93e467fad9a21ecfe7f156652ac",
     "grade": true,
     "grade_id": "A-2a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tf_idf.analyzer == 'word'\n",
    "assert tf_idf.max_features == 2100\n",
    "assert tf_idf.tokenizer == word_tokenize\n",
    "assert tf_idf.stop_words == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0c6b6ab1d30a8d760d3316b8fe2517c",
     "grade": false,
     "grade_id": "cell-b9b4c5df67dcdaad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2b) \n",
    "Again, using `train_test_split`, split the `movie_df['review']` and `movie_df['Y']` into a training set and a test set. \n",
    "\n",
    "Name these variables as:\n",
    "- `movie_train_X_tf_idf` and `movie_test_X_tf_idf` for the input\n",
    "- `movie_train_Y_tf_idf` and `movie_test_Y_tf_idf` for the labels\n",
    "\n",
    "We will use the same 80/20 split as in part 1 and same arguments for the parameters `test_size` (0.2) and `random_state` (108). Again, convert `movie_train_X_tf_idf` and `movie_test_X_tf_idf` into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "591708dbcc5c302cd7676f072937d4e8",
     "grade": false,
     "grade_id": "Q-2c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65b9a02989e33c92c2294ec600eb80c3",
     "grade": true,
     "grade_id": "A-2c",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(movie_train_X_tf_idf) == 4000\n",
    "assert len(movie_test_X_tf_idf) == 1000\n",
    "assert movie_train_Y_tf_idf.shape == (4000,)\n",
    "assert movie_test_Y_tf_idf.shape == (1000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b90f1a7a4a98a353e5a7467fb6545230",
     "grade": false,
     "grade_id": "cell-ffac7f563014d29e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2c) Transform Reviews \n",
    "\n",
    "Fit `tf_idf` we created above using the appropriate input data and vectorize `movie_train_X_tf_idf` and `movie_test_X_tf_idf` into vectors. Save the transformed training and test input data into `movie_train_vector_tf_idf` and `movie_test_vector_tf_idf`, respectively. Finally, convert `movie_train_vector_tf_idf` and `movie_test_vector_tf_idf` into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ff37beccacbe2ae69273f42fd5a3147",
     "grade": false,
     "grade_id": "Q-2b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "vocabulary_tf_idf_train = tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "702e0f2e3cf3a838c81c26b6636374dc",
     "grade": true,
     "grade_id": "A-2b",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(movie_train_vector_tf_idf, np.ndarray)\n",
    "assert isinstance(movie_test_vector_tf_idf, np.ndarray)\n",
    "\n",
    "assert \"skills\" in set(tf_idf.stop_words_)\n",
    "assert \"risky\" in set(tf_idf.stop_words_)\n",
    "assert \"adopts\" in set(tf_idf.stop_words_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddfc1b2bd87175ac6924b019c3b277ee",
     "grade": false,
     "grade_id": "cell-96712af487883a5a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2d) Training\n",
    "\n",
    "Train an SVM classifier on the training samples and labels.\n",
    "\n",
    "You need to call the function `train_SVM` you created in part 1. Name the returned object as `movie_tf_idf_classifier`.\n",
    "\n",
    "Note: training your model may take many seconds, up to a few minutes, to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eb6e10b5381e26bae6627ed77281b85",
     "grade": false,
     "grade_id": "Q-2d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84263574bbf2a77a045ed30b0878aee1",
     "grade": true,
     "grade_id": "A-2d",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(movie_tf_idf_classifier, SVC)\n",
    "assert hasattr(movie_tf_idf_classifier, \"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44a29a8cb878877a4b8ad2bc45118ca6",
     "grade": false,
     "grade_id": "cell-e495a3fb363f328e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2e) Prediction\n",
    "\n",
    "Predict the labels for both the training and test samples (the 'X' data).\n",
    "\n",
    "Name the predicted labels on **training samples** as `movie_train_Y_tf_idf_pred`. Name the predicted labels on **testing samples** as `movie_test_Y_tf_idf_pred`\n",
    "\n",
    "Note: this may take a few seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "816245b11f565460b7f1b8bff30b150d",
     "grade": false,
     "grade_id": "Q-2e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2493c1aedb1e3ab34d4be8d274aae56f",
     "grade": false,
     "grade_id": "cell-1a135f4081b1600b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Again, we use `classification_report` to check the performance on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02507f66c3e7b79007d5b397c96d55d",
     "grade": false,
     "grade_id": "cell-afa1a0e6e8f72a98",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Your classifier should be able to reach above 86% accuracy.\n",
    "print(classification_report(movie_train_Y_tf_idf, movie_train_Y_tf_idf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "005069a96a1b54ece4e82c458f51b9ea",
     "grade": false,
     "grade_id": "cell-9d366662c45c6299",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Again, check performance on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea72c0dda099931bb702e89d2eb7152f",
     "grade": false,
     "grade_id": "cell-0d6895d998434cbe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Your classifier should be able to reach around 73% accuracy.\n",
    "print(classification_report(movie_test_Y_tf_idf, movie_test_Y_tf_idf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b96b45fd8241da2a0b67cf51bf335d8",
     "grade": true,
     "grade_id": "A-2e",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "precision, recall, _, _ = precision_recall_fscore_support(movie_train_Y_tf_idf, movie_train_Y_tf_idf_pred)\n",
    "assert np.isclose(precision[0], 0.86, 0.02)\n",
    "assert np.isclose(precision[1], 0.89, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d77da48b624a430f74c88ba37d40601a",
     "grade": false,
     "grade_id": "cell-29e222dd4865bd30",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Written Answer Question\n",
    "\n",
    "How does the performance of the TF-IDF classifier compare to the classifier used in part 1?  And why do you think you see what you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0127d55bda50552dcea96a26fdeef27",
     "grade": true,
     "grade_id": "cell-ac993b2591707522",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0182aff301479004059a74cd0251df65",
     "grade": false,
     "grade_id": "cell-15bf17c90c32702a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part 3: Sentiment Analysis on Customer Review with TF-IDF (2 points)\n",
    "\n",
    "In this part, we will use TF-IDF to analyze the sentiment of some Customer Review (CR) data.\n",
    "\n",
    "The CR data contains around 3771 reviews, and they were all collected from the Amazon website. The reviews are annotated by humans as either positive reviews or negative reviews. In this dataset, the 2 classes are not balanced, as there are twice as many positive reviews as negative reviews.\n",
    "\n",
    "For more information on this dataset, you can visit https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    "In this part, we have already split the data into a training set and a test set, in which the training set has labels for the reviews, but the test set doesn't. \n",
    "\n",
    "The goal is to train an SVM classifier on the training set, and then predict pos/neg for each review in the test set.\n",
    "\n",
    "To do so, we will:\n",
    "- Use the TF-IDF feature engineering method to encode the raw text data into vectors\n",
    "- Train an SVM classifier on the training set\n",
    "- Predict labels for the reviews in the test set\n",
    "\n",
    "The performance of your trained classifier on the test set will be checked by a hidden test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "196f43efeaad1f013535dd78d4b91d8c",
     "grade": false,
     "grade_id": "cell-c78ab60b7a795fbc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3a) Loading the data\n",
    "\n",
    "Customer review task has 2 files\n",
    "- `https://raw.githubusercontent.com/COGS108/A4_Data/refs/heads/main/data/custrev_train.tsv` contains training data with labels\n",
    "- `https://raw.githubusercontent.com/COGS108/A4_Data/refs/heads/main/data/custrev_test.tsv` contains test data without labels which need to be predicted \n",
    "\n",
    "Import the training data into a DataFrame called `CR_train_df`. Set the column names as `index`, `label`, `review`.\n",
    "\n",
    "Import the test data into a DataFrame called `CR_test_df`. Set the column names as `index`, `review`\n",
    "\n",
    "Note that both will need to be imported with `sep` and `header` arguments (like in 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "358b3f36554784c4c1c0cd596b1fac3a",
     "grade": false,
     "grade_id": "Q-3a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_train_file = 'https://raw.githubusercontent.com/COGS108/A4_Data/refs/heads/main/data/custrev_train.tsv'\n",
    "CR_test_file = 'https://raw.githubusercontent.com/COGS108/A4_Data/refs/heads/main/data/custrev_test.tsv'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9e642f52cd3098f07200e2b409c358f",
     "grade": true,
     "grade_id": "A-3a",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_train_df, pd.DataFrame)\n",
    "assert isinstance(CR_test_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) Concatenation\n",
    "Concatenate the 2 DataFrames from the last step into a single DataFrame, and name it `CR_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77cb9f91e11824e5f97cf895bdc4a1ae",
     "grade": false,
     "grade_id": "Q-3b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21f9338bb2a54d6f4e2167a80182a8da",
     "grade": true,
     "grade_id": "A-3b",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(CR_df) == 3771"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b40e336d418362498228412e8b9d93b6",
     "grade": false,
     "grade_id": "cell-090a84f5c2674b36",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3c) Cleaning\n",
    "\n",
    "Convert all labels in `CR_df[\"label\"]` to numerical labels using the `label_converter` function we defined above. Save these numerical labels as a new column named `Y` in CR_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0144c733efbb0bccdcff00556f828467",
     "grade": false,
     "grade_id": "Q-3c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8626303d71130a8886f521a0b05ae815",
     "grade": true,
     "grade_id": "A-3c",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_df['Y'], pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7641b2c3d47e37cf3a3b932d43bd611",
     "grade": false,
     "grade_id": "cell-8fd126d314b8d681",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3d)  Use `tf_idf`\n",
    "\n",
    "Transform reviews `CR_df[\"review\"]` into vectors using the `tf_idf` vectorizer we created in part 2 and convert the result into a numpy array. Save the transformed data into a variable called `CR_X_tf_idf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9b5a50a8bfd01d1a84335933c17e079",
     "grade": false,
     "grade_id": "Q-3d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3da4c1b83f1b8fa3cdfffe0db3ffdaa",
     "grade": true,
     "grade_id": "A-3d",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_X_tf_idf, np.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46656229257d6f24fc6e48b222dd2ef9",
     "grade": false,
     "grade_id": "cell-528cadc1a8580ba2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Here we will collect all training samples & numerical labels from `CR_X_tf_idf`. The code provided below will extract all samples with labels from the dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "750c5e6aab0945aee10ac7c78a1a8a26",
     "grade": false,
     "grade_id": "get_data",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# code provided to collect labels\n",
    "CR_train_X = CR_X_tf_idf[~CR_df['Y'].isnull()]\n",
    "CR_train_Y = CR_df['Y'][~CR_df['Y'].isnull()]\n",
    "\n",
    "# Note: if these asserts fail, something went wrong\n",
    "#  Go back and check your code (in part 3) above this cell\n",
    "assert CR_train_X.shape == (3016, 2100)\n",
    "assert CR_train_Y.shape == (3016, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "472449b49b38d3fa878aaa454948bb04",
     "grade": false,
     "grade_id": "cell-d8b7615b2d8506b3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3e) SVM \n",
    "\n",
    "Train an SVM classifier on the samples `CR_train_X` and the labels `CR_train_Y`:\n",
    "- You need to call the function `train_SVM` you created above.\n",
    "- Name the returned object as `CR_clf`.\n",
    "\n",
    "Note: training your model may take many seconds / up to a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7b2307c4b5cb41d418554659d2ef781",
     "grade": false,
     "grade_id": "Q-3e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be122b0d817296d6fd13cf0013f4a870",
     "grade": true,
     "grade_id": "A-3e",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_clf, SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb50d466ee4a3166d41992778fb3db7e",
     "grade": false,
     "grade_id": "cell-56e632c22794e853",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3f) Predict: training data\n",
    "\n",
    "Predict labels on the training set `CR_train_X` using `CR_clf`, and name the returned variable as `CR_train_Y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8514b0192f4492cf745a2884bb50f09",
     "grade": false,
     "grade_id": "Q-3f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b21aeb226eb9f4b9ab553f67324d8178",
     "grade": false,
     "grade_id": "cell-5393293deccc9d78",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check the classifier accuracy on the train data\n",
    "# Note that your classifier should be able to reach above 80% accuracy.\n",
    "print(classification_report(CR_train_Y, CR_train_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e65533187f0524c7d628556d7a1382c",
     "grade": true,
     "grade_id": "A-3f",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "precision, recall, _, _ = precision_recall_fscore_support(CR_train_Y, CR_train_Y_pred)\n",
    "assert np.isclose(precision[0], 0.84, 0.02)\n",
    "assert np.isclose(precision[1], 0.86, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2085cd75c1e039b89511b5893799203",
     "grade": false,
     "grade_id": "cell-8fd0d23508a04891",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Collect all test samples from CR_X_tf_idf\n",
    "CR_test_X = CR_X_tf_idf[CR_df['Y'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "839c7027e514241085c71c26005d3e0b",
     "grade": false,
     "grade_id": "cell-7c227f5d7445fcdf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3g)  Predict: test set\n",
    "Predict the labels on the test set `CR_test_X`. Create a pandas DataFrame called `CR_test_label_pred` and store the numeric predictions in a column called `'label'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89b10231bb5f2120e5665c31ae3f2e73",
     "grade": false,
     "grade_id": "cell-b6603f47310799dc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55ed85c7a4f11fe1982a880ec8566e08",
     "grade": true,
     "grade_id": "A-3g",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_test_X, np.ndarray)\n",
    "assert isinstance(CR_test_label_pred, pd.DataFrame)\n",
    "assert CR_test_label_pred.columns == 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_test_label_pred['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "160f8e3acaacde56a815499d60be352a",
     "grade": false,
     "grade_id": "cell-f91666d22c0dac60",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3h) Convert labels\n",
    "\n",
    "Using the `label_converter` function, convert the predicted numerical labels `CR_test_label_pred['label']` back to string labels (\"pos\" and \"neg\").\n",
    "\n",
    "Create a column called `label` in `CR_test_df` to store the converted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dffb957468c0c3f47c0d9ad1d4043078",
     "grade": false,
     "grade_id": "Q-3h",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea43af4e7bf55cadffd160b191085e8f",
     "grade": true,
     "grade_id": "A-3h",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_test_df['label'], pd.Series)\n",
    "assert set(CR_test_df['label']) == {'neg', 'pos'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41680299f76e1beb79f92d4422cd30f7",
     "grade": false,
     "grade_id": "cell-24356cb4367a5c1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The hidden assignments tests for the cell above will check that your model predicts the right number of pos/neg reviews in the test data provided. \n",
    "\n",
    "We now have a model that can predict positive or negative sentiment! \n",
    "\n",
    "Briefly in your own words, think about and write a quick example of when and why it might be useful to computationally analyze the sentiment of text data. And in contrast, when it might not work so well. [This whole answer can/should be a couple of sentences].\n",
    "\n",
    "After you answer this question, you are done! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fa8493f1dc08831d45aa221dc494dc2",
     "grade": true,
     "grade_id": "cell-bf8fe759022c76b4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9fb06a8436f63b96c7bb58c88b11e99",
     "grade": false,
     "grade_id": "cell-97b817a9de5a8398",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Complete! \n",
    "\n",
    "Good work! Have a look back over your answers, and also make sure to `Restart & Run All` from the kernel menu to double check that everything is working properly. While you can typically use the 'Validate' button above, which runs your notebook from top to bottom and checks to ensure all `assert` statements pass silently, ***this may fail on this assignment as the code takes too long to run. Use Restart & Run All instead***. When you are ready, submit on datahub!\n",
    "\n",
    "Note that ***the final validation is for your reassurance and is not a required step***. You can submit without validating. You can also submit without passing all asserts (for partial credit on the assignment). We grade whatever is submitted on datahub. We will grade your most recent submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
